model_list:
  # Sonnet 4.5 (default, global endpoint - better availability, no premium)
  - model_name: claude-sonnet-4-5-20250929
    litellm_params:
      model: vertex_ai/claude-sonnet-4-5@20250929
      vertex_project: eci-global-it
      vertex_location: global
    model_info:
      input_cost_per_token: 0.000003
      output_cost_per_token: 0.000015
  - model_name: claude-sonnet-4-5
    litellm_params:
      model: vertex_ai/claude-sonnet-4-5@20250929
      vertex_project: eci-global-it
      vertex_location: global
    model_info:
      input_cost_per_token: 0.000003
      output_cost_per_token: 0.000015

  # Haiku 4.5 (global endpoint - better availability, no premium)
  - model_name: claude-haiku-4-5-20251001
    litellm_params:
      model: vertex_ai/claude-haiku-4-5@20251001
      vertex_project: eci-global-it
      vertex_location: global
    model_info:
      input_cost_per_token: 0.000001  # $1.00 per 1M tokens
      output_cost_per_token: 0.000005  # $5.00 per 1M tokens
  - model_name: claude-haiku-4-5
    litellm_params:
      model: vertex_ai/claude-haiku-4-5@20251001
      vertex_project: eci-global-it
      vertex_location: global
    model_info:
      input_cost_per_token: 0.000001  # $1.00 per 1M tokens
      output_cost_per_token: 0.000005  # $5.00 per 1M tokens

  # Opus 4.5 (global endpoint)
  - model_name: claude-opus-4-5
    litellm_params:
      model: vertex_ai/claude-opus-4-5@20251101
      vertex_project: eci-global-it
      vertex_location: global
    model_info:
      input_cost_per_token: 0.000005  # $5.00 per 1M tokens
      output_cost_per_token: 0.000025  # $25.00 per 1M tokens

  # Opus 4.6 (global endpoint - better availability, no premium)
  - model_name: claude-opus-4-6
    litellm_params:
      model: vertex_ai/claude-opus-4-6
      vertex_project: eci-global-it
      vertex_location: global
    model_info:
      input_cost_per_token: 0.000005  # $5.00 per 1M tokens
      output_cost_per_token: 0.000025  # $25.00 per 1M tokens

  # Opus 4.6 (regional us-east5 - for data residency requirements, +10% cost)
  - model_name: claude-opus-4-6-regional
    litellm_params:
      model: vertex_ai/claude-opus-4-6
      vertex_project: eci-global-it
      vertex_location: us-east5
    model_info:
      input_cost_per_token: 0.0000055  # $5.50 per 1M tokens (10% premium)
      output_cost_per_token: 0.0000275  # $27.50 per 1M tokens (10% premium)

  # Custom model entry (Vertex AI @ format, global endpoint)
  - model_name: "claude-sonnet-4-5@20250929"
    litellm_params:
      model: vertex_ai/claude-sonnet-4-5@20250929
      vertex_project: eci-global-it
      vertex_location: global
    model_info:
      input_cost_per_token: 0.000003
      output_cost_per_token: 0.000015

router_settings:
  num_retries: 3
  timeout: 300  # 5 min — Opus completions can be long
  allowed_fails: 3
  cooldown_time: 5

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  # Vertex AI doesn't support count_tokens — block to avoid 500s
  disable_endpoints:
    - "/v1/messages/count_tokens"
    - "v1/messages/count_tokens"

litellm_settings:
  drop_params: true
  modify_params: true
  disable_token_count: true
  callbacks: ["langfuse"]
  # Default metadata/tags for all requests (for Langfuse filtering)
  default_team_settings:
    - team_id: "claude-code"
      metadata:
        tags: ["claude-code"]
        source: "claude-code-cli"

environment_variables:
  LANGFUSE_PUBLIC_KEY: os.environ/LANGFUSE_PUBLIC_KEY
  LANGFUSE_SECRET_KEY: os.environ/LANGFUSE_SECRET_KEY
  LANGFUSE_HOST: os.environ/LANGFUSE_HOST
